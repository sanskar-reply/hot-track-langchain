{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "94f8a023",
      "metadata": {
        "id": "94f8a023"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/retrievers/recursive_retriever_nodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "025f3e20-aec9-491c-8c90-234aed406a25",
      "metadata": {
        "id": "025f3e20-aec9-491c-8c90-234aed406a25"
      },
      "source": [
        "# Recursive Retriever + Node References\n",
        "\n",
        "This guide shows how you can use recursive retrieval to traverse node relationships and fetch nodes based on \"references\".\n",
        "\n",
        "Node references are a powerful concept. When you first perform retrieval, you may want to retrieve the reference as opposed to the raw text. You can have multiple references point to the same node.\n",
        "\n",
        "In this guide we explore some different usages of node references:\n",
        "- **Chunk references**: Different chunk sizes referring to a bigger chunk\n",
        "- **Metadata references**: Summaries + Generated Questions referring to a bigger chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee583e89-a508-493e-b232-42e520ce19de",
      "metadata": {
        "id": "ee583e89-a508-493e-b232-42e520ce19de"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%env OPENAI_API_KEY=YOUR_OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "691e6b21",
      "metadata": {
        "id": "691e6b21"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42164863",
      "metadata": {
        "id": "42164863"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "273f38de-e79a-4ce2-ad4e-2c70afc33f34",
      "metadata": {
        "id": "273f38de-e79a-4ce2-ad4e-2c70afc33f34"
      },
      "source": [
        "## Load Data + Setup\n",
        "\n",
        "In this section we download the Llama 2 paper and create an initial set of nodes (chunk size 1024)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb829ef-b54b-4095-a832-6d1d115aa645",
      "metadata": {
        "id": "1eb829ef-b54b-4095-a832-6d1d115aa645",
        "outputId": "98ca29bb-e16f-4d6b-a0c7-5f89e0e03502"
      },
      "outputs": [],
      "source": [
        "%mkdir -p 'data/'\n",
        "%wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd97455-5ff3-43ee-8222-f496ec234dc7",
      "metadata": {
        "id": "6cd97455-5ff3-43ee-8222-f496ec234dc7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from llama_hub.file.pdf.base import PDFReader\n",
        "from llama_index.response.notebook_utils import display_source_node\n",
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a",
      "metadata": {
        "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a"
      },
      "outputs": [],
      "source": [
        "loader = PDFReader()\n",
        "docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "493e5492-a6ae-4e3e-aa23-274c0605b165",
      "metadata": {
        "id": "493e5492-a6ae-4e3e-aa23-274c0605b165"
      },
      "outputs": [],
      "source": [
        "from llama_index import Document\n",
        "\n",
        "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
        "docs = [Document(text=doc_text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c2abcd3-6cae-49dd-8719-9b738d000652",
      "metadata": {
        "id": "7c2abcd3-6cae-49dd-8719-9b738d000652"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SentenceSplitter\n",
        "from llama_index.schema import IndexNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b997ae-9260-4ae7-af2f-0f8d38625d32",
      "metadata": {
        "id": "91b997ae-9260-4ae7-af2f-0f8d38625d32"
      },
      "outputs": [],
      "source": [
        "node_parser = SentenceSplitter(chunk_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cda44b0-fd27-4255-9aa7-08d358635772",
      "metadata": {
        "id": "0cda44b0-fd27-4255-9aa7-08d358635772"
      },
      "outputs": [],
      "source": [
        "base_nodes = node_parser.get_nodes_from_documents(docs)\n",
        "# set node ids to be a constant\n",
        "for idx, node in enumerate(base_nodes):\n",
        "    node.id_ = f\"node-{idx}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e47623-b67d-45d6-9b24-33ba84719f1f",
      "metadata": {
        "id": "38e47623-b67d-45d6-9b24-33ba84719f1f"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings import resolve_embed_model\n",
        "\n",
        "embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f43ebab2-fc46-41ea-8a92-9148994d793f",
      "metadata": {
        "id": "f43ebab2-fc46-41ea-8a92-9148994d793f"
      },
      "source": [
        "## Baseline Retriever\n",
        "\n",
        "Define a baseline retriever that simply fetches the top-k raw text nodes by embedding similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704fb3da-710e-4ad9-b630-565911917f0c",
      "metadata": {
        "id": "704fb3da-710e-4ad9-b630-565911917f0c"
      },
      "outputs": [],
      "source": [
        "base_index = VectorStoreIndex(base_nodes, service_context=service_context)\n",
        "base_retriever = base_index.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160c339b-601a-486b-9e17-dd6cc9f133ea",
      "metadata": {
        "id": "160c339b-601a-486b-9e17-dd6cc9f133ea"
      },
      "outputs": [],
      "source": [
        "retrievals = base_retriever.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "632610f3-c8f2-440a-ab27-5ca7d65f882a",
      "metadata": {
        "id": "632610f3-c8f2-440a-ab27-5ca7d65f882a",
        "outputId": "484f7116-aa3c-4ee7-b12b-b3a7bc3a3fe3"
      },
      "outputs": [],
      "source": [
        "for n in retrievals:\n",
        "    display_source_node(n, source_length=1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96dd8a01-1cae-4614-beab-5b5e0434fefe",
      "metadata": {
        "id": "96dd8a01-1cae-4614-beab-5b5e0434fefe"
      },
      "outputs": [],
      "source": [
        "query_engine_base = RetrieverQueryEngine.from_args(\n",
        "    base_retriever, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ae66ff-7d12-45c8-9b1a-adb20bd3c7ea",
      "metadata": {
        "id": "82ae66ff-7d12-45c8-9b1a-adb20bd3c7ea",
        "outputId": "701fb99d-8f5a-45f1-db67-d52ed65268ed"
      },
      "outputs": [],
      "source": [
        "response = query_engine_base.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5431df3-d255-4492-bce4-bbebde6f2306",
      "metadata": {
        "id": "d5431df3-d255-4492-bce4-bbebde6f2306"
      },
      "source": [
        "## Chunk References: Smaller Child Chunks Referring to Bigger Parent Chunk\n",
        "\n",
        "In this usage example, we show how to build a graph of smaller chunks pointing to bigger parent chunks.\n",
        "\n",
        "During query-time, we retrieve smaller chunks, but we follow references to bigger chunks. This allows us to have more context for synthesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c784d8-71e6-42bc-84d9-a2aea4217b8b",
      "metadata": {
        "id": "49c784d8-71e6-42bc-84d9-a2aea4217b8b"
      },
      "outputs": [],
      "source": [
        "sub_chunk_sizes = [128, 256, 512]\n",
        "sub_node_parsers = [\n",
        "    SentenceSplitter(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n",
        "]\n",
        "\n",
        "all_nodes = []\n",
        "for base_node in base_nodes:\n",
        "    for n in sub_node_parsers:\n",
        "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
        "        sub_inodes = [\n",
        "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
        "        ]\n",
        "        all_nodes.extend(sub_inodes)\n",
        "\n",
        "    # also add original node to node\n",
        "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
        "    all_nodes.append(original_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d614088-b122-40ad-811a-29cc0c2a295e",
      "metadata": {
        "id": "2d614088-b122-40ad-811a-29cc0c2a295e"
      },
      "outputs": [],
      "source": [
        "all_nodes_dict = {n.node_id: n for n in all_nodes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44ef2d5-0342-4073-831f-f35dd6f04dc0",
      "metadata": {
        "id": "a44ef2d5-0342-4073-831f-f35dd6f04dc0"
      },
      "outputs": [],
      "source": [
        "vector_index_chunk = VectorStoreIndex(\n",
        "    all_nodes, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06af99f-02be-4055-a6ea-3071ffe8fc8a",
      "metadata": {
        "id": "c06af99f-02be-4055-a6ea-3071ffe8fc8a"
      },
      "outputs": [],
      "source": [
        "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7c5e43-45b5-42d6-afc5-cb81ed3cb211",
      "metadata": {
        "id": "4c7c5e43-45b5-42d6-afc5-cb81ed3cb211"
      },
      "outputs": [],
      "source": [
        "retriever_chunk = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e9f7bcb-5442-4d2d-a7eb-814b68ebb45c",
      "metadata": {
        "id": "9e9f7bcb-5442-4d2d-a7eb-814b68ebb45c",
        "outputId": "17b6cd1d-7b0a-4190-afc5-0d117cb6594a"
      },
      "outputs": [],
      "source": [
        "nodes = retriever_chunk.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "for node in nodes:\n",
        "    display_source_node(node, source_length=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411f26ad-d13b-4858-938e-efcfa899e8cd",
      "metadata": {
        "id": "411f26ad-d13b-4858-938e-efcfa899e8cd"
      },
      "outputs": [],
      "source": [
        "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
        "    retriever_chunk, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd98366-0d5f-4d04-87cd-b811990b7485",
      "metadata": {
        "id": "4cd98366-0d5f-4d04-87cd-b811990b7485",
        "outputId": "5a455d01-232e-4bab-ddeb-12d10f69450c"
      },
      "outputs": [],
      "source": [
        "response = query_engine_chunk.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bcc7379-c077-40b7-ba4e-f47f80def0c7",
      "metadata": {
        "id": "3bcc7379-c077-40b7-ba4e-f47f80def0c7"
      },
      "source": [
        "## Metadata References: Summaries + Generated Questions referring to a bigger chunk\n",
        "\n",
        "In this usage example, we show how to define additional context that references the source node.\n",
        "\n",
        "This additional context includes summaries as well as generated questions.\n",
        "\n",
        "During query-time, we retrieve smaller chunks, but we follow references to bigger chunks. This allows us to have more context for synthesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3c4f8f",
      "metadata": {
        "id": "7e3c4f8f"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e40c5e-4868-487f-aaf4-f333aa4bda66",
      "metadata": {
        "id": "24e40c5e-4868-487f-aaf4-f333aa4bda66"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SentenceSplitter\n",
        "from llama_index.schema import IndexNode\n",
        "from llama_index.extractors import (\n",
        "    SummaryExtractor,\n",
        "    QuestionsAnsweredExtractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5d6f87-790e-4b82-abb2-cc6944678b00",
      "metadata": {
        "id": "5c5d6f87-790e-4b82-abb2-cc6944678b00"
      },
      "outputs": [],
      "source": [
        "extractors = [\n",
        "    SummaryExtractor(summaries=[\"self\"], show_progress=True),\n",
        "    QuestionsAnsweredExtractor(questions=5, show_progress=True),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e47c706c-940e-499d-b742-eaf09a230b0d",
      "metadata": {
        "id": "e47c706c-940e-499d-b742-eaf09a230b0d",
        "outputId": "403112a3-d20b-434a-863a-25a21dc2eb5f"
      },
      "outputs": [],
      "source": [
        "# run metadata extractor across base nodes, get back dictionaries\n",
        "node_to_metadata = {}\n",
        "for extractor in extractors:\n",
        "    metadata_dicts = extractor.extract(base_nodes)\n",
        "    for node, metadata in zip(base_nodes, metadata_dicts):\n",
        "        if node.node_id not in node_to_metadata:\n",
        "            node_to_metadata[node.node_id] = metadata\n",
        "        else:\n",
        "            node_to_metadata[node.node_id].update(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2873327d-420a-4778-a83b-6fdf7aa21bcd",
      "metadata": {
        "id": "2873327d-420a-4778-a83b-6fdf7aa21bcd"
      },
      "outputs": [],
      "source": [
        "# cache metadata dicts\n",
        "def save_metadata_dicts(path, data):\n",
        "    with open(path, \"w\") as fp:\n",
        "        json.dump(data, fp)\n",
        "\n",
        "\n",
        "def load_metadata_dicts(path):\n",
        "    with open(path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e318efb2-9afa-4414-b37f-71738d73d01d",
      "metadata": {
        "id": "e318efb2-9afa-4414-b37f-71738d73d01d"
      },
      "outputs": [],
      "source": [
        "save_metadata_dicts(\"data/llama2_metadata_dicts.json\", node_to_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edce99f-8a96-4539-95e7-62aeeabb2ce9",
      "metadata": {
        "id": "4edce99f-8a96-4539-95e7-62aeeabb2ce9"
      },
      "outputs": [],
      "source": [
        "metadata_dicts = load_metadata_dicts(\"data/llama2_metadata_dicts.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18d2109-5fcb-4fd5-b147-23897fed8787",
      "metadata": {
        "id": "f18d2109-5fcb-4fd5-b147-23897fed8787"
      },
      "outputs": [],
      "source": [
        "# all nodes consists of source nodes, along with metadata\n",
        "import copy\n",
        "\n",
        "all_nodes = copy.deepcopy(base_nodes)\n",
        "for node_id, metadata in node_to_metadata.items():\n",
        "    for val in metadata.values():\n",
        "        all_nodes.append(IndexNode(text=val, index_id=node_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f90ada6-0969-40cc-a4ec-3579b4900cdd",
      "metadata": {
        "id": "8f90ada6-0969-40cc-a4ec-3579b4900cdd"
      },
      "outputs": [],
      "source": [
        "all_nodes_dict = {n.node_id: n for n in all_nodes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22abc768-83d5-41d0-84f0-533899c76894",
      "metadata": {
        "id": "22abc768-83d5-41d0-84f0-533899c76894"
      },
      "outputs": [],
      "source": [
        "## Load index into vector index\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "service_context = ServiceContext.from_defaults(llm=llm)\n",
        "\n",
        "vector_index_metadata = VectorStoreIndex(\n",
        "    all_nodes, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d53938a-1322-41b1-ad11-169b13b9805a",
      "metadata": {
        "id": "0d53938a-1322-41b1-ad11-169b13b9805a"
      },
      "outputs": [],
      "source": [
        "vector_retriever_metadata = vector_index_metadata.as_retriever(\n",
        "    similarity_top_k=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ae791f-c183-4ad4-9a3a-253288ded5a7",
      "metadata": {
        "id": "37ae791f-c183-4ad4-9a3a-253288ded5a7"
      },
      "outputs": [],
      "source": [
        "retriever_metadata = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_metadata},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd85685-19eb-44cc-ad27-1d163eaddad6",
      "metadata": {
        "id": "3cd85685-19eb-44cc-ad27-1d163eaddad6",
        "outputId": "892e6041-3f7f-4631-ff76-1e6deaa872e8"
      },
      "outputs": [],
      "source": [
        "nodes = retriever_metadata.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "for node in nodes:\n",
        "    display_source_node(node, source_length=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5285854a-69a6-4bc4-a2a5-1004cc790a63",
      "metadata": {
        "id": "5285854a-69a6-4bc4-a2a5-1004cc790a63"
      },
      "outputs": [],
      "source": [
        "query_engine_metadata = RetrieverQueryEngine.from_args(\n",
        "    retriever_metadata, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0ada5c-9a83-4517-bbb7-899d4415d68a",
      "metadata": {
        "id": "4e0ada5c-9a83-4517-bbb7-899d4415d68a",
        "outputId": "3b5b9fc4-e4a9-4528-e2f0-09f14fec8435"
      },
      "outputs": [],
      "source": [
        "response = query_engine_metadata.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9973bdca-d179-47d6-bd96-2631b36e1d94",
      "metadata": {
        "id": "9973bdca-d179-47d6-bd96-2631b36e1d94"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We evaluate how well our recursive retrieval + node reference methods work. We evaluate both chunk references as well as metadata references. We use embedding similarity lookup to retrieve the reference nodes.\n",
        "\n",
        "We compare both methods against a baseline retriever where we fetch the raw nodes directly.\n",
        "\n",
        "In terms of metrics, we evaluate using both hit-rate and MRR."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3a30b7-2eb2-4eae-b0b9-1d4ec26ac915",
      "metadata": {
        "id": "1b3a30b7-2eb2-4eae-b0b9-1d4ec26ac915"
      },
      "source": [
        "### Dataset Generation\n",
        "\n",
        "We first generate a dataset of questions from the set of text chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe8ae8a-a2b2-4515-bcff-1145e14ede3d",
      "metadata": {
        "id": "3fe8ae8a-a2b2-4515-bcff-1145e14ede3d"
      },
      "outputs": [],
      "source": [
        "from llama_index.evaluation import (\n",
        "    generate_question_context_pairs,\n",
        "    EmbeddingQAFinetuneDataset,\n",
        ")\n",
        "from llama_index.llms import OpenAI\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef1b43d-996b-4b0a-becb-1cec08d9f8c3",
      "metadata": {
        "id": "eef1b43d-996b-4b0a-becb-1cec08d9f8c3",
        "outputId": "94584ba7-d2d6-4c0e-c799-d224c73ae3bc"
      },
      "outputs": [],
      "source": [
        "eval_dataset = generate_question_context_pairs(\n",
        "    base_nodes, OpenAI(model=\"gpt-3.5-turbo\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd3e2507-9157-48a5-909b-18eeb9ec01d4",
      "metadata": {
        "id": "bd3e2507-9157-48a5-909b-18eeb9ec01d4"
      },
      "outputs": [],
      "source": [
        "eval_dataset.save_json(\"data/llama2_eval_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "611f07af-2006-4158-8dc6-59d11a269c8d",
      "metadata": {
        "id": "611f07af-2006-4158-8dc6-59d11a269c8d"
      },
      "outputs": [],
      "source": [
        "# optional\n",
        "eval_dataset = EmbeddingQAFinetuneDataset.from_json(\n",
        "    \"data/llama2_eval_dataset.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4782a6-f3da-453f-93be-7683ed15b508",
      "metadata": {
        "id": "fb4782a6-f3da-453f-93be-7683ed15b508"
      },
      "source": [
        "### Compare Results\n",
        "\n",
        "We run evaluations on each of the retrievers to measure hit rate and MRR.\n",
        "\n",
        "We find that retrievers with node references (either chunk or metadata) tend to perform better than retrieving the raw chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87798866-11bc-4f7f-b8aa-0a023309492f",
      "metadata": {
        "id": "87798866-11bc-4f7f-b8aa-0a023309492f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from llama_index.evaluation import RetrieverEvaluator, get_retrieval_results_df\n",
        "\n",
        "# set vector retriever similarity top k to higher\n",
        "top_k = 10\n",
        "\n",
        "\n",
        "def display_results(names, results_arr):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    hit_rates = []\n",
        "    mrrs = []\n",
        "    for name, eval_results in zip(names, results_arr):\n",
        "        metric_dicts = []\n",
        "        for eval_result in eval_results:\n",
        "            metric_dict = eval_result.metric_vals_dict\n",
        "            metric_dicts.append(metric_dict)\n",
        "        results_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "        hit_rate = results_df[\"hit_rate\"].mean()\n",
        "        mrr = results_df[\"mrr\"].mean()\n",
        "        hit_rates.append(hit_rate)\n",
        "        mrrs.append(mrr)\n",
        "\n",
        "    final_df = pd.DataFrame(\n",
        "        {\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs}\n",
        "    )\n",
        "    display(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d142c6-0374-43ec-af31-e02d246bd815",
      "metadata": {
        "id": "a6d142c6-0374-43ec-af31-e02d246bd815"
      },
      "outputs": [],
      "source": [
        "vector_retriever_chunk = vector_index_chunk.as_retriever(\n",
        "    similarity_top_k=top_k\n",
        ")\n",
        "retriever_chunk = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
        ")\n",
        "# try it out on an entire dataset\n",
        "results_chunk = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae448fe7-3a66-45a6-8e8e-6ed3950e61b8",
      "metadata": {
        "id": "ae448fe7-3a66-45a6-8e8e-6ed3950e61b8"
      },
      "outputs": [],
      "source": [
        "vector_retriever_metadata = vector_index_metadata.as_retriever(\n",
        "    similarity_top_k=top_k\n",
        ")\n",
        "retriever_metadata = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_metadata},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever_metadata\n",
        ")\n",
        "# try it out on an entire dataset\n",
        "results_metadata = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3fc029-7ccc-4ec4-b391-b7b86744b5d8",
      "metadata": {
        "id": "3d3fc029-7ccc-4ec4-b391-b7b86744b5d8",
        "outputId": "d6773cf4-64cb-49bc-e389-17ace67b7b21"
      },
      "outputs": [],
      "source": [
        "base_retriever = base_index.as_retriever(similarity_top_k=10)\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
        ")\n",
        "# try it out on an entire dataset\n",
        "results_base = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef0cd73-b1ad-4ec6-931f-357d2ceebd65",
      "metadata": {
        "id": "4ef0cd73-b1ad-4ec6-931f-357d2ceebd65",
        "outputId": "870e599f-6e16-4c68-a812-0866c2bff38b"
      },
      "outputs": [],
      "source": [
        "full_results_df = get_retrieval_results_df(\n",
        "    [\n",
        "        \"Base Retriever\",\n",
        "        \"Retriever (Chunk References)\",\n",
        "        \"Retriever (Metadata References)\",\n",
        "    ],\n",
        "    [results_base, results_chunk, results_metadata],\n",
        ")\n",
        "display(full_results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
